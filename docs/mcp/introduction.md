# MCP Server 介绍

**MCP（Model Context Protocol）** 是一种模型上下文协议，用于将结构化业务数据实时提供给 AI 模型，提升其对业务语境的理解能力。基于 **Tapdata** 提供的 MCP 服务，您可以将来自多个异构系统的数据整合、脱敏并发布为实时上下文视图，供 LLM（大语言模型）或 AI Agent 动态拉取。该方案特别适用于对数据时效性与合规性要求高的企业场景，如金融风控、智能客服、个性化推荐等。

## 背景介绍

随着企业数字化转型的加速，越来越多的企业开始使用 AI 模型进行实时业务决策，然而在实际应用中，却面临着下述问题：

- AI 模型通常缺乏实时业务数据的有效输入，导致推理准确性不足和幻觉问题。
- 企业的数据通常分散于不同的系统，如客户关系管理（CRM）、核心银行系统、企业资源计划（ERP）等，形成数据孤岛问题。
- 受限于数据安全和合规要求，AI 模型通常无法直接访问原始数据库。

![TapData MCP Server 工作原理介绍](../images/tapdata_mcp_server_introduction.png)

为解决这些问题，Tapdata 提供了 MCP 服务，通过标准化的 SSE 协议，结合实时物化视图与数据脱敏加工能力，将结构化上下文实时、安全、高效地推送给 AI 模型。模型**无需直连**数据库，即可精准获取业务数据上下文，显著提升推理准确性，加速 AI 能力在企业中的可信落地，构建统一的“AI 上下文服务层”。

## 功能优势

- **丰富的数据源接入能力，打通上下游数据孤岛**

  支持 100+ 主流数据库与 SaaS 系统接入，实现异构数据的实时采集与同步，为上下文生成提供统一的数据基础。

- **数据模型编辑与宽表构建能力**

  通过图形化任务设计面板，可将多张关联表转换为结构化宽表视图，简化模型输入字段准备过程。

- **高性能物化视图，降低模型推理延迟**

  基于中间数据源构建实时物化视图，支持预聚合与裁剪，避免 AI 模型访问源库，有效提升上下文加载性能。

- **标准化上下文发布接口，兼容主流模型框架**

  支持通过 SSE 协议流式发布上下文数据，也可通过无代码方式暴露 REST API，适配各类 LLM 和智能体接入方式。

- **企业级数据安全与合规保障**

  提供字段级脱敏、行过滤、权限管控等能力，确保上下文数据安全可控，满足金融等高敏感行业的合规要求。

## 场景示例（Todo）



## 了解更多

- [快速上手 TapData MCP Server](quick-start.md)